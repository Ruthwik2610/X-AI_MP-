{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c60ea8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Installing and checking requiered packages\n",
    "\n",
    "# !pip show rdflib pandas numpy scikit-learn shap lime matplotlib ipykernel\n",
    "# !pip install rdflib shap lime\n",
    "!pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "346924a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import gzip\n",
    "from rdflib import Graph\n",
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22e395a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import rdflib\n",
    "\n",
    "# Load the graph\n",
    "g = rdflib.Graph()\n",
    "g.parse(\"data/aifbfixed_complete.n3\", format=\"n3\")\n",
    "\n",
    "print(f\"Number of triples in graph: {len(g)}\")\n",
    "\n",
    "# List some triples to see data structure\n",
    "for i, triple in enumerate(g):\n",
    "    if i > 10:\n",
    "        break\n",
    "    print(triple)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e019b1b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_df = pd.read_csv(\"data/trainingSet.tsv\", sep=\"\\t\")\n",
    "test_df = pd.read_csv(\"data/testSet.tsv\", sep=\"\\t\")\n",
    "complete_df = pd.read_csv(\"data/completeDataset.tsv\", sep=\"\\t\")\n",
    "\n",
    "print(train_df.head())\n",
    "print(test_df.head())\n",
    "print(complete_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea4b831",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Train shape:\", train_df.shape)\n",
    "print(\"Test shape:\", test_df.shape)\n",
    "\n",
    "print(\"Train label distribution:\")\n",
    "print(train_df['label_affiliation'].value_counts(normalize=True))\n",
    "\n",
    "print(\"Test label distribution:\")\n",
    "print(test_df['label_affiliation'].value_counts(normalize=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af7e9f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c1306da",
   "metadata": {},
   "outputs": [],
   "source": [
    "persons_train = train_df['person'].unique()\n",
    "persons_test = test_df['person'].unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc08200a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def extract_features(graph, entities):\n",
    "    entity_features = {}\n",
    "    \n",
    "    for entity in entities:\n",
    "        features = defaultdict(int)\n",
    "        \n",
    "        # For every triple where entity is subject\n",
    "        for _, predicate, obj in graph.triples((rdflib.URIRef(entity), None, None)):\n",
    "            pred_str = str(predicate)\n",
    "            if isinstance(obj, rdflib.URIRef):\n",
    "                obj_str = str(obj)\n",
    "                feature_name = f\"{pred_str}={obj_str}\"\n",
    "            else:\n",
    "                # For literals, you can choose to ignore or keep simplified\n",
    "                obj_str = str(obj)\n",
    "                feature_name = f\"{pred_str}={obj_str}\"\n",
    "            \n",
    "            # Mark feature presence as 1\n",
    "            features[feature_name] = 1\n",
    "        \n",
    "        entity_features[entity] = features\n",
    "    \n",
    "    return entity_features\n",
    "\n",
    "# Example usage:\n",
    "entity_features_train = extract_features(g, persons_train)\n",
    "entity_features_test = extract_features(g, persons_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b58fee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def build_feature_df(entity_features, feature_cols=None):\n",
    "    # Convert dict of dicts to DataFrame\n",
    "    df = pd.DataFrame.from_dict(entity_features, orient='index').fillna(0)\n",
    "    \n",
    "    # Ensure columns are consistent (important for train/test)\n",
    "    if feature_cols is not None:\n",
    "        # Add missing columns\n",
    "        for col in feature_cols:\n",
    "            if col not in df.columns:\n",
    "                df[col] = 0\n",
    "        # Remove extra columns not in feature_cols\n",
    "        df = df[feature_cols]\n",
    "    else:\n",
    "        feature_cols = df.columns.tolist()\n",
    "    \n",
    "    return df, feature_cols\n",
    "\n",
    "# Build train features DataFrame and get columns\n",
    "X_train, feature_cols = build_feature_df(entity_features_train)\n",
    "\n",
    "# Build test features DataFrame using same columns\n",
    "X_test, _ = build_feature_df(entity_features_test, feature_cols=feature_cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14678daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Align labels with feature rows by matching the 'person' index\n",
    "y_train = train_df.set_index('person').loc[X_train.index]['label_affiliation']\n",
    "y_test = test_df.set_index('person').loc[X_test.index]['label_affiliation']\n",
    "\n",
    "# Encode labels to integers for training and testing\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "\n",
    "# Fit LabelEncoder on training labels only\n",
    "y_train_enc = le.fit_transform(y_train)\n",
    "\n",
    "# Transform test labels with the same encoder (do NOT fit again)\n",
    "y_test_enc = le.transform(y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6059021",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "rf = RandomForestClassifier(random_state=42, class_weight='balanced', n_estimators=100, max_depth=10)\n",
    "# rf.fit(X_train, y_train_enc)\n",
    "# y_pred = rf.predict(X_test)\n",
    "\n",
    "# print(\"Test Accuracy:\", accuracy_score(y_test_enc, y_pred))\n",
    "# print(classification_report(y_test_enc, y_pred, target_names=le.classes_))\n",
    "\n",
    "# Train your model with encoded labels\n",
    "rf.fit(X_train, y_train_enc)\n",
    "\n",
    "# Predict encoded labels\n",
    "y_pred_enc = rf.predict(X_test)\n",
    "\n",
    "# Evaluate using encoded test labels and label encoder classes\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "print(\"Accuracy:\", accuracy_score(y_test_enc, y_pred_enc))\n",
    "print(classification_report(y_test_enc, y_pred_enc, target_names=le.classes_, zero_division=0))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "891a316b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"X_train index matches train_df 'person' index:\", all(X_train.index == train_df['person']))\n",
    "print(\"X_test index matches test_df 'person' index:\", all(X_test.index == test_df['person']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3cf6fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_indexed = train_df.set_index('person')\n",
    "test_df_indexed = test_df.set_index('person')\n",
    "\n",
    "y_train = train_df_indexed.loc[X_train.index, 'label_affiliation']\n",
    "y_test = test_df_indexed.loc[X_test.index, 'label_affiliation']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8312fa6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels_set = set(y_test.unique())\n",
    "train_labels_set = set(y_train.unique())\n",
    "\n",
    "unseen_labels = test_labels_set - train_labels_set\n",
    "print(\"Unseen labels in test set:\", unseen_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a5e22b",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_test_mask = y_test.isin(le.classes_)\n",
    "y_test = y_test[valid_test_mask]\n",
    "X_test = X_test.loc[valid_test_mask]\n",
    "\n",
    "y_test_enc = le.transform(y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fff00a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training label counts:\")\n",
    "print(y_train.value_counts(normalize=True))\n",
    "\n",
    "print(\"Test label counts:\")\n",
    "print(y_test.value_counts(normalize=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db9bb44c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"X_train shape: {X_train.shape}, y_train length: {len(y_train)}\")\n",
    "print(f\"X_test shape: {X_test.shape}, y_test length: {len(y_test)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7a3462d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Assuming X_train, X_test are DataFrames with indices matching train_df and test_df respectively\n",
    "\n",
    "# Align y_train, y_test by indexing train/test df on 'person'\n",
    "train_df_indexed = train_df.set_index('person')\n",
    "test_df_indexed = test_df.set_index('person')\n",
    "\n",
    "y_train = train_df_indexed.loc[X_train.index, 'label_affiliation']\n",
    "y_test = test_df_indexed.loc[X_test.index, 'label_affiliation']\n",
    "\n",
    "# Check unseen labels (should be empty)\n",
    "unseen_labels = set(y_test.unique()) - set(y_train.unique())\n",
    "assert len(unseen_labels) == 0, f\"Unseen test labels: {unseen_labels}\"\n",
    "\n",
    "# Encode labels\n",
    "le = LabelEncoder()\n",
    "y_train_enc = le.fit_transform(y_train)\n",
    "y_test_enc = le.transform(y_test)\n",
    "\n",
    "# Sanity checks\n",
    "print(\"Train label distribution:\")\n",
    "for idx, count in zip(*np.unique(y_train_enc, return_counts=True)):\n",
    "    print(f\" - Class {le.inverse_transform([idx])[0]}: {count / len(y_train_enc):.3f}\")\n",
    "\n",
    "print(\"\\nTest label distribution:\")\n",
    "for idx, count in zip(*np.unique(y_test_enc, return_counts=True)):\n",
    "    print(f\" - Class {le.inverse_transform([idx])[0]}: {count / len(y_test_enc):.3f}\")\n",
    "\n",
    "print(f\"\\nShapes: X_train={X_train.shape}, y_train={y_train_enc.shape}\")\n",
    "print(f\"Shapes: X_test={X_test.shape}, y_test={y_test_enc.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "565d3203",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "model = RandomForestClassifier(random_state=42, class_weight='balanced', n_estimators=100, max_depth=10)\n",
    "model.fit(X_train, y_train_enc)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(\"Test Accuracy:\", accuracy_score(y_test_enc, y_pred))\n",
    "print(classification_report(y_test_enc, y_pred, target_names=le.classes_, zero_division=0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08b28cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "common_indices = set(X_train.index).intersection(set(X_test.index))\n",
    "print(f\"Common indices between train and test: {len(common_indices)}\")  # Should be 0\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Calculate correlation or mutual info if numeric features\n",
    "correlations = X_train.apply(lambda col: np.corrcoef(col, y_train_enc)[0,1] if np.issubdtype(col.dtype, np.number) else 0)\n",
    "print(\"Top correlated features with label:\")\n",
    "print(correlations.abs().sort_values(ascending=False).head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88f5817c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify leak features (example: those containing 'affiliation=')\n",
    "leak_features = [col for col in X_train.columns if 'affiliation=' in col]\n",
    "\n",
    "print(\"Features leaking label info:\", leak_features)\n",
    "\n",
    "# Remove these features\n",
    "X_train_filtered = X_train.drop(columns=leak_features)\n",
    "X_test_filtered = X_test.drop(columns=leak_features)\n",
    "\n",
    "print(f\"Original feature count: {X_train.shape[1]}, after removal: {X_train_filtered.shape[1]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9841b992",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# 1. Identify label-leaking features (containing 'affiliation=')\n",
    "leak_features = [col for col in X_train.columns if 'affiliation=' in col]\n",
    "\n",
    "print(f\"Features leaking label info: {leak_features}\")\n",
    "\n",
    "# 2. Remove these leak features from train and test\n",
    "X_train_filtered = X_train.drop(columns=leak_features)\n",
    "X_test_filtered = X_test.drop(columns=leak_features)\n",
    "\n",
    "print(f\"Original feature count: {X_train.shape[1]}, after removal: {X_train_filtered.shape[1]}\")\n",
    "\n",
    "# 3. Retrain classifier on filtered features\n",
    "rf_filtered = RandomForestClassifier(random_state=42, n_estimators=100, max_depth=10)\n",
    "rf_filtered.fit(X_train_filtered, y_train_enc)\n",
    "\n",
    "# 4. Predict on filtered test set\n",
    "y_pred_filtered = rf_filtered.predict(X_test_filtered)\n",
    "\n",
    "# 5. Evaluate\n",
    "acc_filtered = accuracy_score(y_test_enc, y_pred_filtered)\n",
    "print(f\"Test Accuracy (filtered features): {acc_filtered:.4f}\")\n",
    "\n",
    "print(\"\\nClassification Report (filtered features):\")\n",
    "print(classification_report(y_test_enc, y_pred_filtered, target_names=le.classes_, zero_division=0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1772b00",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e439a5c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada17462",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbcf7874",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acaff571",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4571b5a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
